{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Youssef1Moustafa/Olymbic_prediction/blob/main/prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5457729-fc40-4523-8bda-d31a53934075",
      "metadata": {
        "id": "f5457729-fc40-4523-8bda-d31a53934075"
      },
      "outputs": [],
      "source": [
        "#!pip install lightgbm\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a22cca8-c3e8-4448-b1ac-7e4e6c41602d",
      "metadata": {
        "id": "8a22cca8-c3e8-4448-b1ac-7e4e6c41602d"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('olymbic.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jm5j5yOAN9Uo",
      "metadata": {
        "id": "Jm5j5yOAN9Uo"
      },
      "outputs": [],
      "source": [
        "df = df.drop(['Gold_Count','Silver_Count','Bronze_Count','Total_Medals','Total_Medals_country'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53722258-e156-4bc8-93af-7917dea39abd",
      "metadata": {
        "id": "53722258-e156-4bc8-93af-7917dea39abd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#selected_features = positive_corr_delivery_type['Feature'].tolist()\n",
        "#X = df[selected_features]\n",
        "X = df.drop(['won_or_not'], axis=1)\n",
        "y = df['won_or_not']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "204d4e29-68b2-4d3a-b0f2-08f43020befa",
      "metadata": {
        "id": "204d4e29-68b2-4d3a-b0f2-08f43020befa"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f724332-6393-4eba-bc40-0c67d6d9ed67",
      "metadata": {
        "id": "9f724332-6393-4eba-bc40-0c67d6d9ed67"
      },
      "outputs": [],
      "source": [
        "print(f\"Resampled class distribution: \\n{y_train_resampled.value_counts()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fdca9be-c359-4e63-bfe0-9ca42a911976",
      "metadata": {
        "id": "0fdca9be-c359-4e63-bfe0-9ca42a911976"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cdabbe3-6793-4ee0-8fd0-43f34b4a662b",
      "metadata": {
        "id": "2cdabbe3-6793-4ee0-8fd0-43f34b4a662b"
      },
      "outputs": [],
      "source": [
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b75a29e-8652-4d9b-8520-7a950ec7cef8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998
        },
        "id": "8b75a29e-8652-4d9b-8520-7a950ec7cef8",
        "outputId": "6d323b95-de98-438d-8123-824bc3195733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Logistic Regression ---\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.91      0.92     21722\n",
            "           1       0.56      0.68      0.61      3847\n",
            "\n",
            "    accuracy                           0.87     25569\n",
            "   macro avg       0.75      0.79      0.77     25569\n",
            "weighted avg       0.88      0.87      0.88     25569\n",
            "\n",
            "ROC-AUC Score: 0.69\n",
            "\n",
            "--- Decision Tree ---\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     21722\n",
            "           1       0.90      1.00      0.95      3847\n",
            "\n",
            "    accuracy                           0.98     25569\n",
            "   macro avg       0.95      0.99      0.97     25569\n",
            "weighted avg       0.99      0.98      0.98     25569\n",
            "\n",
            "ROC-AUC Score: 0.99\n",
            "\n",
            "--- Random Forest ---\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     21722\n",
            "           1       0.95      1.00      0.97      3847\n",
            "\n",
            "    accuracy                           0.99     25569\n",
            "   macro avg       0.97      1.00      0.98     25569\n",
            "weighted avg       0.99      0.99      0.99     25569\n",
            "\n",
            "ROC-AUC Score: 1.00\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-204da82bdfaf>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtrain_and_evaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-204da82bdfaf>\u001b[0m in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m(model, model_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 5: Define a function to train and evaluate models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_and_evaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"--- {model_name} ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_status_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Step 5: Define a function to train and evaluate models\n",
        "def train_and_evaluate_model(model, model_name):\n",
        "    model.fit(X_train_resampled, y_train_resampled)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"--- {model_name} ---\")\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "    print(f\"ROC-AUC Score: {roc_auc:.2f}\\n\")\n",
        "\n",
        "# Step 6: Train and evaluate different models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(class_weight='balanced', max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(class_weight='balanced', random_state=42),\n",
        "    #\"Support Vector Machine\": SVC(class_weight='balanced', probability=True),\n",
        "    \"XGBoost\": xgb.XGBClassifier(scale_pos_weight=(len(y) - sum(y)) / sum(y), random_state=42),\n",
        "    \"LightGBM\": lgb.LGBMClassifier(class_weight='balanced', random_state=42)\n",
        "}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    train_and_evaluate_model(model, model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c26db09a-08ce-4944-a73f-c85a51846f69",
      "metadata": {
        "id": "c26db09a-08ce-4944-a73f-c85a51846f69"
      },
      "source": [
        "# Importance features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee64bc4b-6909-4bad-b87a-d0d53de60f35",
      "metadata": {
        "id": "ee64bc4b-6909-4bad-b87a-d0d53de60f35"
      },
      "outputs": [],
      "source": [
        "X = df[['NOC','Country','Sport','Event']]\n",
        "y = df['won_or_not']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09f70d1f-21f9-4292-94e5-b44f37b9b272",
      "metadata": {
        "id": "09f70d1f-21f9-4292-94e5-b44f37b9b272"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b5eab04-81c7-4f50-ae14-2eee2b2b6ee8",
      "metadata": {
        "id": "6b5eab04-81c7-4f50-ae14-2eee2b2b6ee8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab5c4cd-4cbe-46b8-f67c-f317efda5074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampled class distribution: \n",
            "won_or_not\n",
            "0    50788\n",
            "1    50788\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(f\"Resampled class distribution: \\n{y_train_resampled.value_counts()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a06b369-faa9-4bae-8b3b-b603ec87a812",
      "metadata": {
        "id": "7a06b369-faa9-4bae-8b3b-b603ec87a812"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68adf292-fd57-4a9d-ad53-903b674e6284",
      "metadata": {
        "id": "68adf292-fd57-4a9d-ad53-903b674e6284",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9860d8ac-0031-476b-a86d-fc555e1c6586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.81      0.87     21722\n",
            "           1       0.41      0.73      0.52      3847\n",
            "\n",
            "    accuracy                           0.80     25569\n",
            "   macro avg       0.68      0.77      0.70     25569\n",
            "weighted avg       0.86      0.80      0.82     25569\n",
            "\n",
            "ROC-AUC Score: 0.84\n"
          ]
        }
      ],
      "source": [
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "print(f\"ROC-AUC Score: {roc_auc:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db29647b-ea6a-4b40-b90d-5c5fb19f543d",
      "metadata": {
        "id": "db29647b-ea6a-4b40-b90d-5c5fb19f543d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c20083e-dc9b-4bae-b857-16003f4d994c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Logistic Regression ---\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.54      0.67     21722\n",
            "           1       0.18      0.58      0.28      3847\n",
            "\n",
            "    accuracy                           0.54     25569\n",
            "   macro avg       0.53      0.56      0.47     25569\n",
            "weighted avg       0.77      0.54      0.61     25569\n",
            "\n",
            "ROC-AUC Score: 0.58\n",
            "\n",
            "--- Decision Tree ---\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.82      0.88     21722\n",
            "           1       0.41      0.71      0.52      3847\n",
            "\n",
            "    accuracy                           0.80     25569\n",
            "   macro avg       0.68      0.76      0.70     25569\n",
            "weighted avg       0.86      0.80      0.82     25569\n",
            "\n",
            "ROC-AUC Score: 0.83\n",
            "\n",
            "--- Random Forest ---\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.81      0.87     21722\n",
            "           1       0.41      0.73      0.52      3847\n",
            "\n",
            "    accuracy                           0.80     25569\n",
            "   macro avg       0.68      0.77      0.70     25569\n",
            "weighted avg       0.86      0.80      0.82     25569\n",
            "\n",
            "ROC-AUC Score: 0.84\n",
            "\n",
            "--- XGBoost ---\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.41      0.57     21722\n",
            "           1       0.22      0.94      0.36      3847\n",
            "\n",
            "    accuracy                           0.49     25569\n",
            "   macro avg       0.60      0.68      0.47     25569\n",
            "weighted avg       0.86      0.49      0.54     25569\n",
            "\n",
            "ROC-AUC Score: 0.83\n",
            "\n",
            "[LightGBM] [Info] Number of positive: 50788, number of negative: 50788\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005153 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 779\n",
            "[LightGBM] [Info] Number of data points in the train set: 101576, number of used features: 4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "--- LightGBM ---\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.72      0.82     21722\n",
            "           1       0.33      0.76      0.46      3847\n",
            "\n",
            "    accuracy                           0.73     25569\n",
            "   macro avg       0.64      0.74      0.64     25569\n",
            "weighted avg       0.85      0.73      0.76     25569\n",
            "\n",
            "ROC-AUC Score: 0.81\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Define a function to train and evaluate models\n",
        "def train_and_evaluate_model(model, model_name):\n",
        "    model.fit(X_train_resampled, y_train_resampled)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"--- {model_name} ---\")\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "    print(f\"ROC-AUC Score: {roc_auc:.2f}\\n\")\n",
        "\n",
        "# Step 6: Train and evaluate different models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(class_weight='balanced', max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(class_weight='balanced', random_state=42),\n",
        "    \"XGBoost\": xgb.XGBClassifier(scale_pos_weight=(len(y) - sum(y)) / sum(y), random_state=42),\n",
        "    \"LightGBM\": lgb.LGBMClassifier(class_weight='balanced', random_state=42)\n",
        "}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    train_and_evaluate_model(model, model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77414277-30f8-45bd-b6d0-9a2db1d3316b",
      "metadata": {
        "id": "77414277-30f8-45bd-b6d0-9a2db1d3316b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0155cd9d-d0b7-441d-d494-dea0c1755b2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 0.8006\n",
            "Accuracy for this fold: 0.7997\n",
            "Accuracy for this fold: 0.7964\n",
            "Accuracy for this fold: 0.7990\n",
            "Accuracy for this fold: 0.8017\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Step 4: Apply K-Fold Cross-Validation and store accuracies\n",
        "accuracies = []\n",
        "\n",
        "for train_index, test_index in kf.split(X, y):\n",
        "    # Split into train and test for this fold\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Apply SMOTE on the training data to handle imbalance\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    # Train the RandomForest model\n",
        "    model = RandomForestClassifier(random_state=42)\n",
        "    model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy for this fold\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(acc)\n",
        "    print(f\"Accuracy for this fold: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9c6e6ac-cd34-487e-bff9-aa94a8787c48",
      "metadata": {
        "id": "c9c6e6ac-cd34-487e-bff9-aa94a8787c48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db1abb73-c29f-4b95-a4db-ca3d524a6647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mean Accuracy across all folds: 0.7995\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# Step 5: Calculate the mean accuracy across all folds\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "print(f\"\\nMean Accuracy across all folds: {mean_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f556e409-ee09-43f1-a0b3-22cd59c7e6b2",
      "metadata": {
        "id": "f556e409-ee09-43f1-a0b3-22cd59c7e6b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "5219d282-64e9-4c43-b95f-1aa56bd8ef4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this fold: 0.8006\n",
            "Accuracy for this fold: 0.7997\n",
            "Accuracy for this fold: 0.7964\n",
            "Accuracy for this fold: 0.7990\n",
            "Accuracy for this fold: 0.8017\n",
            "\n",
            "Mean Accuracy: 0.7995\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'joblib' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-4932a8e13d3a>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Save the best model to a .pkl file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'best_model.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model saved as 'best_model.pkl'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'joblib' is not defined"
          ]
        }
      ],
      "source": [
        "import pickle as pkl\n",
        "# Initialize StratifiedKFold and SMOTE\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "accuracies = []\n",
        "best_model = None\n",
        "best_accuracy = 0\n",
        "\n",
        "# K-Fold Cross-Validation with SMOTE and RandomForest\n",
        "for train_index, test_index in kf.split(X, y):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Apply SMOTE to the training data\n",
        "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    # Train the RandomForest model\n",
        "    model = RandomForestClassifier(random_state=42)\n",
        "    model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(acc)\n",
        "    print(f\"Accuracy for this fold: {acc:.4f}\")\n",
        "\n",
        "    # Save the best model\n",
        "    if acc > best_accuracy:\n",
        "        best_accuracy = acc\n",
        "        best_model = model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean accuracy\n",
        "import joblib\n",
        "\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "print(f\"\\nMean Accuracy: {mean_accuracy:.4f}\")\n",
        "\n",
        "# Save the best model to a .pkl file\n",
        "joblib.dump(best_model, 'best_model.pkl')\n",
        "print(\"Model saved as 'best_model.pkl'.\")\n",
        "\n",
        "# Load the model (Example)\n",
        "loaded_model = joblib.load('best_model.pkl')\n",
        "print(\"Model loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l12ZFL6kyRXi",
        "outputId": "3f1fdaa4-eabc-40b6-f3d7-a73298b3f749"
      },
      "id": "l12ZFL6kyRXi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mean Accuracy: 0.7995\n",
            "Model saved as 'best_model.pkl'.\n",
            "Model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2m8rPI00yTHu"
      },
      "id": "2m8rPI00yTHu",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}